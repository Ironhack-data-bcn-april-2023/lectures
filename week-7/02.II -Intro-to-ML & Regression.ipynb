{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b52a763",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# Intro to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-american",
   "metadata": {},
   "source": [
    "![elgifderigor](https://media.giphy.com/media/NsBknNwmmWE8WU1q2U/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-vault",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Some-concepts\" data-toc-modified-id=\"Some-concepts-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Some concepts</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimators\" data-toc-modified-id=\"Estimators-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Estimators</a></span></li><li><span><a href=\"#Bias-Error\" data-toc-modified-id=\"Bias-Error-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Bias Error</a></span></li><li><span><a href=\"#Variance-Error\" data-toc-modified-id=\"Variance-Error-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Variance Error</a></span></li></ul></li><li><span><a href=\"#Types-of-Machine-Learning\" data-toc-modified-id=\"Types-of-Machine-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Types of Machine Learning</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Features</a></span></li><li><span><a href=\"#Underfitting-and-Overfitting\" data-toc-modified-id=\"Underfitting-and-Overfitting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Underfitting and Overfitting</a></span></li><li><span><a href=\"#Let's-do-it?\" data-toc-modified-id=\"Let's-do-it?-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Let's do it?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Let's-practice-ML-with-a-regression-example\" data-toc-modified-id=\"Let's-practice-ML-with-a-regression-example-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Let's practice ML with a regression example</a></span></li><li><span><a href=\"#We-load-a-dataset\" data-toc-modified-id=\"We-load-a-dataset-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>We load a dataset</a></span></li><li><span><a href=\"#Train-/-Test-Split---What-is-this?\" data-toc-modified-id=\"Train-/-Test-Split---What-is-this?-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Train / Test Split - What is this?</a></span></li><li><span><a href=\"#Preparing-data-for-train-test-split\" data-toc-modified-id=\"Preparing-data-for-train-test-split-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Preparing data for train test split</a></span></li><li><span><a href=\"#Optional-train-test-split-parameters\" data-toc-modified-id=\"Optional-train-test-split-parameters-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Optional train test split parameters</a></span></li><li><span><a href=\"#We-already-have-the-dataset-divided,-now-we-are-going-to-import-a-model-and-train-it\" data-toc-modified-id=\"We-already-have-the-dataset-divided,-now-we-are-going-to-import-a-model-and-train-it-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>We already have the dataset divided, now we are going to import a model and train it</a></span></li><li><span><a href=\"#We-create-our-predictions\" data-toc-modified-id=\"We-create-our-predictions-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>We create our predictions</a></span></li><li><span><a href=\"#We-measure-our-model\" data-toc-modified-id=\"We-measure-our-model-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>We measure our model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-with-a-real-case-of-a-colleague-who-gives-me-data-from-a-house-in-Boston\" data-toc-modified-id=\"Example-with-a-real-case-of-a-colleague-who-gives-me-data-from-a-house-in-Boston-5.8.1\"><span class=\"toc-item-num\">5.8.1&nbsp;&nbsp;</span>Example with a real case of a colleague who gives me data from a house in Boston</a></span></li></ul></li></ul></li><li><span><a href=\"#Extra!-Training-different-models-at-the-same-time\" data-toc-modified-id=\"Extra!-Training-different-models-at-the-same-time-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extra! Training different models at the same time</a></span><ul class=\"toc-item\"><li><span><a href=\"#Store-all-the-models-we-are-going-to-train-in-a-dictionary\" data-toc-modified-id=\"Store-all-the-models-we-are-going-to-train-in-a-dictionary-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Store all the models we are going to train in a dictionary</a></span></li><li><span><a href=\"#Iterate-over-the-models-to-train-them\" data-toc-modified-id=\"Iterate-over-the-models-to-train-them-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Iterate over the models to train them</a></span></li></ul></li><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Feature Selection</a></span></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Cross Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#We-make-CV-to-a-single-model\" data-toc-modified-id=\"We-make-CV-to-a-single-model-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>We make CV to a single model</a></span></li><li><span><a href=\"#CV-looping-through-all-models\" data-toc-modified-id=\"CV-looping-through-all-models-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>CV looping through all models</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fa2aa",
   "metadata": {},
   "source": [
    "![sklearn](../images/ext_sklearn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8bdd5",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Some concepts\n",
    "To understand how a machine learning algorithm learns from data to predict an outcome, it is essential to understand the underlying concepts that go into training an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab999f7d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Estimators\n",
    "Estimate is a statistical term for finding some estimate of an unknown parameter, given some data. Point estimation is the attempt to provide the best prediction of some quantity of interest.\n",
    "The amount of interest can be:\n",
    " - A single parameter\n",
    " - A vector of parameters - for example, the weights in linear regression\n",
    " - A full function\n",
    "\n",
    "### Bias Error\n",
    "\n",
    "It is the difference between the expected prediction of our model and the true values. Although in the end our goal is always to build models that can predict data very close to the true values, it is not always that easy because some algorithms are simply too rigid to learn complex signals from the data set.\n",
    "\n",
    "Imagine fitting a linear regression to a data set that has a non-linear pattern, no matter how many more observations you collect, a linear regression will not be able to model the curves on that data. This is known as underfitting.\n",
    "\n",
    "In general, parametric algorithms like linear regression have a high bias that makes them quick to learn and easier to understand, but generally less flexible. In turn, they have a lower predictive performance in complex problems.\n",
    "\n",
    "### Variance Error\n",
    "\n",
    "It refers to the amount that the estimate of the objective function will change if different training data is used. The objective function is estimated from the training data by a Machine Learning algorithm, so we should expect the algorithm to have some variance. Ideally it shouldn't change too much from one training dataset to another, which means the algorithm is good at choosing the hidden underlying mapping between the input and output variables.\n",
    "\n",
    "Machine learning algorithms that have a large variance are heavily influenced by the details of the training data, this means that the details of the training influence the number and types of parameters used to characterize the mapping function.\n",
    "\n",
    "Generally, non-parametric machine learning algorithms that have a lot of flexibility have a lot of variation.\n",
    "\n",
    "- Low variance: suggests small changes in the estimate of the objective function with changes in the training data set.\n",
    "- High variance: suggests large changes in the estimate of the objective function with changes in the training data set.\n",
    "Low variance machine learning algorithms include: linear regression, linear discriminant analysis, and logistic regression.\n",
    "\n",
    "On the other hand, the algorithms with high variance are: decision trees, k-nearest neighbors and support vector machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee9c76",
   "metadata": {},
   "source": [
    "<img src=\"https://nvsyashwanth.github.io/machinelearningmaster/assets/images/bias_variance.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b75a54",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Types of Machine Learning\n",
    "**- Supervised**\n",
    "The model is trained with labeled data, that is, with data whose basic truth is known. When presented with data and a label, the model infers patterns.\n",
    "\n",
    "**- Unsupervised**\n",
    "There are no basic truths. The model looks for previously undetected patterns, with which to separate the different data points into different clusters.\n",
    "\n",
    "**- Reinforcement**\n",
    "There is also no basic truth. The model's action is valued and a reward or punishment is given accordingly. The goal of the model is to get as many rewards as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bb12e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Features\n",
    "**Features** are independent individual variables that act as input to your system. Prediction models use features to\n",
    "make predictions.\n",
    "\n",
    "**Target**\n",
    "The goal is the output of the input variables. They can be the individual classes to which the input variables are assigned in the case of a classification problem or the range of output values ​​in a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f061c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Underfitting and Overfitting\n",
    "Splitting a data set can also be important to detect if your model suffers from one of two common problems, called underfitting and overfitting:\n",
    "\n",
    "**underfitting** is usually the consequence of a model being unable to encapsulate relationships between data. For example, this can occur when trying to represent nonlinear relationships with a linear model. Underfitted models are likely to perform poorly on both the training and test sets.\n",
    "\n",
    "**overfitting** usually occurs when a model has an excessively complex structure and learns both relationships between data and noise. These models tend to have poor generalization ability. Although they work well with training data, they tend to perform poorly with unseen (test) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42891daf",
   "metadata": {},
   "source": [
    "<img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/52874iE986B6E19F3248CF?v=v2\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d818b71",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Bias and variance in machine learning --> https://www.analyticslane.com/2019/05/24/the-concepts-of-bias-and-variance-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb69f4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Let's do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc9340",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Let's practice ML with a regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71991430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eb3fc2d",
   "metadata": {},
   "source": [
    "[Datasets source](https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-house-prices-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3c508",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6812d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467203f2",
   "metadata": {},
   "source": [
    "- CRIM - per capita crime rate by town\n",
    "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS - proportion of non-retail business acres per town.\n",
    "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- NOX - nitric oxides concentration (parts per 10 million)\n",
    "- RM - average number of rooms per dwelling\n",
    "- AGE - proportion of owner-occupied units built prior to 1940\n",
    "- DIS - weighted distances to five Boston employment centres\n",
    "- RAD - index of accessibility to radial highways\n",
    "- TAX - full-value property-tax rate per 10,000\n",
    "- PTRATIO - pupil-teacher ratio by town\n",
    "- B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT - % lower status of the population\n",
    "- MEDV - Median value of owner-occupied homes in 1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57701d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Train / Test Split - What is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e15f7",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/kaggle_train_test_split.svg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab1891",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The training-test split is a technique for evaluating the performance of a machine learning algorithm.\n",
    "\n",
    "It can be used for classification or regression problems and can be used for any supervised learning algorithm.\n",
    "\n",
    "The procedure consists of taking a data set and dividing it into two subsets. The first subset is used to fit the model and is called the training data set. The second subset is not used to train the model; instead, the model is given the input from the dataset, then predictions are made and compared to expected values. This second data set is called the test data set.\n",
    "\n",
    "Training dataset: Used to fit the machine learning model.\n",
    "Test dataset: Used to evaluate the fitted machine learning model.\n",
    "The goal is to estimate the performance of the machine learning model with new data: data not used to train the model.\n",
    "\n",
    "This is how we hope to use the model in practice. That is, fit it on the available data with known inputs and outputs, and then make predictions about new examples in the future where we don't have the expected output or target values.\n",
    "\n",
    "The training-test procedure is adequate when a sufficiently large data set is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7641d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Preparing data for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633d381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dd02e98",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Optional train test split parameters\n",
    "\n",
    "**train_size** is the number that defines the size of the training set. If you provide a float then it must be between 0.0 and 1.0 and will define the part of the dataset used for testing. If you provide an int, then it will represent the total number of training samples. The default value is None.\n",
    "\n",
    "**test_size** is the number that defines the size of the test suite. It is very similar to train_size. You must provide either train_size or test_size. If neither is provided, the default portion of the dataset to use for testing is 0.25, or 25 percent.\n",
    "\n",
    "**random_state** is the object that controls randomness during splitting. It can be an int or an instance of RandomState. The default value is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c8111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2813454a",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We already have the dataset divided, now we are going to import a model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78d3df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5570f80d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We create our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c0f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e96d06c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We measure our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9145ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE, error: {metrics.mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE, error: {metrics.mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"RMSE, error: {np.sqrt(metrics.mean_squared_error(y_test, y_pred))}\")\n",
    "print(f\"r2: {metrics.r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fae727",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Example with a real case of a colleague who gives me data from a house in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\n",
    "    \"CRIM\": 0.04337,\n",
    "    \"ZN\": 30,\n",
    "    \"INDUS\": 8,\n",
    "    \"CHAS\": 0, \n",
    "    \"NOX\": 0.2345,\n",
    "    \"RM\": 9.8,\n",
    "    \"AGE\":30,\n",
    "    \"DIS\": 3.55,\n",
    "    \"RAD\": 4.0,\n",
    "    \"TAX\": 345, \n",
    "    \"PTRATIO\": 19.0,\n",
    "    \"B\":343,\n",
    "    \"LSTAT\": 4.5,\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ebaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd821128",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Extra! Training different models at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63a201",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Store all the models we are going to train in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b17e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lr\": LinReg(),\n",
    "    \"ridge\": Ridge(),\n",
    "    \"lasso\": Lasso(),\n",
    "    \"sgd\": SGDRegressor(),\n",
    "    \"knn\": KNeighborsRegressor(),\n",
    "    \"grad\": GradientBoostingRegressor(),\n",
    "    \"svr\": SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8c182",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Iterate over the models to train them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067bc0ac",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/kaggle_train_test_split.svg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e4067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"------------{name}------------\\n\")\n",
    "    print(f\"MAE, error: {metrics.mean_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"MSE, error: {metrics.mean_squared_error(y_test, y_pred)}\")\n",
    "    print(f\"RMSE, error: {np.sqrt(metrics.mean_squared_error(y_test, y_pred))}\")\n",
    "    print(f\"r2: {metrics.r2_score(y_test, y_pred)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fa133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a18ea72b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003082cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca4400",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Given an external estimator that assigns weights to features (for example, the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select them by recursively considering smaller and smaller sets of features. First, the estimator is trained with the initial set of features and the importance of each of them is obtained through some specific or callable attribute. The less important features of the current set are then removed. This procedure is repeated recursively on the pruned set until the desired number of features to select is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ecdf71",
   "metadata": {},
   "source": [
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162d535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2625af8c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The ranking of the features, so that ranking_[i] corresponds to the ranking position of the i-th feature. Selected features (i.e. best estimates) are assigned rank 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df0329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cba144d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Cross Validation\n",
    "Let's read a bit of the [documentation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "**Wikipedia tells us**\n",
    "Cross validation or cross-validation is a technique used to evaluate the results of a statistical analysis and ensure that they are independent of the partition between training and test data. It consists of repeating and calculating the arithmetic mean obtained from the evaluation measures on different partitions. It is used in environments where the main objective is prediction and the accuracy of a model that will be carried out in practice is to be estimated. It is a technique widely used in artificial intelligence projects to validate generated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as cvs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-walnut",
   "metadata": {},
   "source": [
    "![kfoldcv](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c9d4d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Cross-Validation: K-fold with 5 splits\n",
    "What we normally do when training the model is to pass all the records to it and have it do the fit().\n",
    "With K-Folds -in this example of 5 splits- to train, instead of passing all the records directly to the model, we will do this:\n",
    "\n",
    "**Iterate 5 times:**\n",
    "- We will set aside 1/5 of samples\n",
    "- We train the model with the remaining 4/5 samples\n",
    "- We will measure the r2 obtained on those we had set aside.\n",
    "- This means that we do 5 independent trainings.\n",
    "- The final R2 will be the average of the 5 previous r2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae76a93",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We make CV to a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56b4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d76a1794",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### CV looping through all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148105f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ea6610",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a002731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-a",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
