{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparable-lancaster",
   "metadata": {},
   "source": [
    "# Machine Learning - Supervised learning - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-baseline",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Exploring-the-data\" data-toc-modified-id=\"Exploring-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Exploring the data</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Logistic regression</a></span></li><li><span><a href=\"#Let's-do-it\" data-toc-modified-id=\"Let's-do-it-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Let's do it</a></span><ul class=\"toc-item\"><li><span><a href=\"#Let's-train-a-model:-without-splitting-just-yet\" data-toc-modified-id=\"Let's-train-a-model:-without-splitting-just-yet-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Let's train a model: without splitting just yet</a></span></li><li><span><a href=\"#Let's-create-a-prediction-column-for-the-entire-dataframe:-skipping-metrics-for-now\" data-toc-modified-id=\"Let's-create-a-prediction-column-for-the-entire-dataframe:-skipping-metrics-for-now-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Let's create a prediction column for the entire dataframe: skipping metrics for now</a></span></li><li><span><a href=\"#Confusion-matrix-with-our-data\" data-toc-modified-id=\"Confusion-matrix-with-our-data-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Confusion matrix with our data</a></span></li></ul></li><li><span><a href=\"#We-do-the-same-with-many-predictors\" data-toc-modified-id=\"We-do-the-same-with-many-predictors-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>We do the same with many predictors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Review-of-Train-Test-Split-/-DIVISION-IN-TRAIN-TEST\" data-toc-modified-id=\"Review-of-Train-Test-Split-/-DIVISION-IN-TRAIN-TEST-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Review of Train Test Split / DIVISION IN TRAIN TEST</a></span></li><li><span><a href=\"#Let's-see-what-we-got\" data-toc-modified-id=\"Let's-see-what-we-got-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Let's see what we got</a></span><ul class=\"toc-item\"><li><span><a href=\"#part-of-train\" data-toc-modified-id=\"part-of-train-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>part of train</a></span></li><li><span><a href=\"#test-part\" data-toc-modified-id=\"test-part-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>test part</a></span></li></ul></li></ul></li><li><span><a href=\"#Predict-Proba\" data-toc-modified-id=\"Predict-Proba-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Predict Proba</a></span></li><li><span><a href=\"#Metrics!\" data-toc-modified-id=\"Metrics!-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Metrics!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Confusion-matrix\" data-toc-modified-id=\"Confusion-matrix-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Confusion matrix</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Precision\" data-toc-modified-id=\"Precision-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Precision</a></span></li><li><span><a href=\"#Recall\" data-toc-modified-id=\"Recall-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Recall</a></span></li><li><span><a href=\"#Differentiating-precision-and-recall\" data-toc-modified-id=\"Differentiating-precision-and-recall-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Differentiating precision and recall</a></span></li><li><span><a href=\"#F1-Score\" data-toc-modified-id=\"F1-Score-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>F1 Score</a></span></li></ul></li><li><span><a href=\"#Other-classification-models\" data-toc-modified-id=\"Other-classification-models-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Other classification models</a></span></li><li><span><a href=\"#We-make-predictions-and-measure\" data-toc-modified-id=\"We-make-predictions-and-measure-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>We make predictions and measure</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-efficiency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Viz mantra\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config Inlinebackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set(rc={'figure.figsize': (16., 9.)})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ec5cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model & split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbe915",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "* **regression** models are used when the target variable is **quantitative**:\n",
    "  - wages\n",
    "  - gas emission\n",
    "  - age of the person in a photo\n",
    "  \n",
    "* **classification**: models are used when the target variable is **qualitative**:\n",
    "  - survive (or not) the Titanic\n",
    "  - repay (or not) a loan\n",
    "  - identify a dog (or not) in a photo\n",
    "  - decide which of 3 plant species this is\n",
    "  - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc16b9",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0671685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "central-applicant",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Documentation:  \n",
    "a) radius (mean of distances from center to points on the perimeter)  \n",
    "b) texture (standard deviation of gray-scale values)  \n",
    "c) perimeter  \n",
    "d) area  \n",
    "e) smoothness (local variation in radius lengths)  \n",
    "f) compactness (perimeter^2 / area - 1.0)  \n",
    "g) concavity (severity of concave portions of the contour)  \n",
    "h) concave points (number of concave portions of the contour)  \n",
    "i) symmetry  \n",
    "j) fractal dimension (\"coastline approximation\" - 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c952f8",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The target variable is `is_cancer`.\n",
    "\n",
    "It is a categorical variable, which takes the possible values ​​$0$ and $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15271b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ed697c5",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Logistic regression\n",
    "Logistic regression is one of the most popular and used algorithms for classification problems. Since it is also relatively uncomplicated and easy to implement, it is often used as a starting model, although it can also produce very high-performance results used in production. Here we are going to talk about Binomial Logistic Regression, which is used for binary results. Multinomial Logistic Regression exists and can be used for multiclass classification problems, but it is used less frequently. We will not cover it in this lesson.\n",
    "\n",
    "Logistic regression is actually a transformed linear regression function. We can see in the image below that if we tried to fit a linear regression to some data with a binary result, we would fit a line that does not predict very well for any value that is not in the extreme values: in the middle there is a lot of area where the line is very far from the points. To make our function closer to the data, we have to transform the function we are using. In this case, it is useful to use a sigmoid function, which estimates an \"S\" shape. Now we can see that our line fits the data much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-supervision",
   "metadata": {},
   "source": [
    "![regresiónlogística](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281070/linear_vs_logistic_regression_edxw03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-people",
   "metadata": {},
   "source": [
    "Refs:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html     \n",
    "https://techdifferences.com/difference-between-linear-and-logistic-regression.html    \n",
    "https://stackoverflow.com/questions/12146914/what-is-the-difference-between-linear-regression-and-logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9882453",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Let's do it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d362ca",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Let's try to predict `is_cancer` using only `mean_radius` as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b92d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fa4958f",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Let's train a model: without splitting just yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-interview",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #instead of LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7a769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec7a8f9e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Let's create a prediction column for the entire dataframe: skipping metrics for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06834b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b5fb0e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Confusion matrix with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe5ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7e3bd4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "* 333 times - **We have predicted NO and it is NO** -> True\n",
    "* 24 times - We have predicted YES and it is NO -> False\n",
    "* 45 times - We have preached NO and it is YES -> False\n",
    "* 167 times - **We have predicted YES and it is YES** -> True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a173fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c140935",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## We do the same with many predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a9a24",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Review of Train Test Split / DIVISION IN TRAIN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca1bd7",
   "metadata": {},
   "source": [
    "![divisióntraintest](../images/traintest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5ed16",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92c833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48b450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48df8055",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Kit-kat (max iter)\n",
    "I get this warning... we'll see hyperparameter tuning, but basically I have to scale my data or make the model more complex with more iterations.\n",
    "```\n",
    "/usr/local/Caskroom/miniconda/base/envs/ironhack/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status =1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d001a3",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Let's see what we got\n",
    "#### part of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46ceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2d9d212",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45a761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47246bd4",
   "metadata": {},
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c9194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a23de6e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-reply",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570699fa",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1615ea5",
   "metadata": {},
   "source": [
    "`metrics`: binary and multi-lable classification [towardsdatasciece](https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b5b377",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Confusion Matrix\n",
    "We are going to explain how the confusion matrix works with a hypothetical marketing example. In this example, we contact 100 customers and 80 of them tell us that they are not interested and 20 of them that they are.\n",
    "\n",
    "Our model (in the example) is not very good, although depending on what metric we use it might appear to be better than it is.\n",
    "\n",
    "We have used as values ​​of the binary classification:\n",
    "\n",
    "- 0: not interested\n",
    "- 1: yes you are interested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-mountain",
   "metadata": {},
   "source": [
    "![matrizdeconfusión](https://www.iartificial.net/wp-content/uploads/2019/11/Matriz-Confusion-Ejemplo.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ce0f2",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "In the confusion matrix on the left you can see the values ​​for this example. In the confusion matrix on the right, the generic names when we use the English nomenclature: True Negative [TN], True Positive [TP], False Positive [FP], False Negative [FN].\n",
    "\n",
    "Tip: to easily remember the confusion matrix:\n",
    "\n",
    "Positive (Positive) or Negative (Negative): refers to the prediction. If the model predicts 1 then it will be positive, and if it predicts 0 it will be negative.\n",
    "True (True) or False (False): refers to whether the prediction is correct or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-thompson",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/conf_matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da995598",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Equivalent with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-clearance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09925f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300e17c7",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74313f6e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Accuracy measures the percentage of cases that the model has got right. This is one of the most used and favorite metrics… that I recommend you avoid! The problem with accuracy is that it can lead to deception, that is, it can make a bad model appear to be much better than it is.\n",
    "The problem of using accuracy on unbalanced data.....\n",
    "\n",
    "• Example: In a data set with 990 positives and 10\n",
    "negatives, a classifier that always predicts “positive”,\n",
    "would have a 0.99 hit rate And yet it's bad!\n",
    "\n",
    "Represents the proportion of samples correctly predicted\n",
    " * The most common metric for ranking 🤔👀\n",
    " * It is useful when\n",
    "  - the data set has balanced classes (similar proportion of True and False)\n",
    "  - there is symmetry between True and False (for example, prediction of \"male\" or \"female\")\n",
    " * **Often misused!** since:\n",
    "  - many problems are not symmetrical (for example, cancer vs. non-cancer)\n",
    "\n",
    "The accuracy is calculated with the following formula:\n",
    "\n",
    "$$accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-olympus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb2dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50fc82f6",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Interpreting this metric, we see that the model has been correct 96% of the diagnoses, that is, it will be wrong 4% of the times it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed0cdd",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bfa8a",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "With the precision metric we can measure the quality of the machine learning model in classification tasks. In the example, it means that accuracy is the answer to the question: what percentage of the customers we contact will be interested?\n",
    "\n",
    "To calculate the precision we will use the following formula:\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "It is the fraction of predicted positive events that are actually positive as shown below\n",
    "\n",
    "This metric is defined as the number of true positive cases over the total number of everything you said was positive. In other words, of everything that the algorithm predicted as positive, it evaluates how much of it was true. One of the examples proposed [here](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9) is to mark an email as spam, when it really was not. Imagine that an anti-spam system has a low precision and marks an email as spam even though it is not, and you end up not reading your sister's wedding invitation.\n",
    "One of the cases where this metric can be used, as the post says, is when the number of false positives has a very important impact. Imagine a classifier that mistakes a diagnosis and you end up amputating a patient's healthy leg.\n",
    "\n",
    "This image marks the data sets selected when calculating precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-difficulty",
   "metadata": {},
   "source": [
    "<img src=\"https://www.iartificial.net/wp-content/uploads/2019/11/precision.webp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7001e79",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Precision = Percentage of POSITIVE predictions that were correct.\n",
    "What proportion of the predicted Positives is actually Positive?\n",
    "We have to look at the total number of predicted Positives (True Positives plus False Positives, TP+FP), and see how many of them are True Positives (TP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-atmosphere",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad555f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb82f8fd",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82dc3a",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The recall metric will inform us about the amount that the machine learning model is capable of identifying. In the example, it refers to the fact that recall is the answer to the question: what percentage of customers are interested are we able to identify?\n",
    "\n",
    "To calculate recall we will use the following formula:\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-tamil",
   "metadata": {},
   "source": [
    "<img src=\"https://www.iartificial.net/wp-content/uploads/2019/11/recall-exhaustividad.webp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083d090",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "It answers a different question: what proportion of real positives is correctly classified?\n",
    "Percentage of positive cases that I have captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-pendant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec025db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2b2e89b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Differentiating precision and recall\n",
    "Despite being similar, they have subtle distinctions.\n",
    "\n",
    "- Precision: How many times is what my model says really true?\n",
    "- Recall: How many times is my model able to identify the truth?\n",
    "\n",
    "Precision focuses on what the model says and then compares it to reality. On the other hand, recall starts from reality, and then evaluates how good the model is at recognizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-parish",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851aaf1",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The F1 value is used to combine the precision and recall measurements into a single value. This is handy because it makes it easier to compare the combined accuracy and recall performance between various solutions.\n",
    "\n",
    "F1 is calculated by taking the harmonic mean between precision and recall:\n",
    "\n",
    "$$F1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-loading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973553a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa19e74b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "I have extracted documentation of the metrics from [this](https://www.iartificial.net/precision-recall-f1-accuracy-in-classification/) exceptionally explained article.\n",
    "But here I leave you more:\n",
    "- https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "- https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "- https://wiki.pathmind.com/accuracy-precision-recall-f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49f9b3",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Other classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-publication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5e835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dcfad00",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## We make predictions and measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b4290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-cleveland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"------------------\")\n",
    "    print(model)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"F1 score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464937e6",
   "metadata": {},
   "source": [
    "# Logistic regression: visual example (only three features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('../datasets/breast_cancer.csv')  # Replace 'your_dataset.csv' with your actual dataset file path\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data[[\"mean_radius\", \"mean_area\", \"mean_symmetry\"]]\n",
    "y = data['is_cancer']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Create a 3D interactive plot with decision boundary\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=X['mean_radius'],\n",
    "        y=X['mean_area'],\n",
    "        z=X['mean_symmetry'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=y,\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Generate a meshgrid of points to create decision boundary\n",
    "x_min, x_max = X['mean_radius'].min() - 1, X['mean_radius'].max() + 1\n",
    "y_min, y_max = X['mean_area'].min() - 1, X['mean_area'].max() + 1\n",
    "z_min, z_max = X['mean_symmetry'].min() - 1, X['mean_symmetry'].max() + 1\n",
    "\n",
    "xx, yy, zz = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1),\n",
    "                         np.arange(z_min, z_max, 0.1))\n",
    "\n",
    "# Predict the probabilities for the meshgrid points\n",
    "mesh_predictions = model.predict_proba(np.c_[xx.ravel(), yy.ravel(), zz.ravel()])\n",
    "mesh_predictions = mesh_predictions[:, 1].reshape(xx.shape)\n",
    "\n",
    "# Add the decision boundary surface to the plot\n",
    "fig.add_trace(go.Surface(x=xx, y=yy, z=zz, name='Decision Boundary',\n",
    "                         surfacecolor=mesh_predictions, colorscale='RdBu',\n",
    "                         showscale=False, opacity=0.9, cmin=0, cmax=1))\n",
    "\n",
    "# Update the layout to have a better viewing angle\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=1.25, y=1.25, z=1.25)\n",
    ")\n",
    "fig.update_layout(scene_camera=camera)\n",
    "\n",
    "# Display the plot\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df2537",
   "metadata": {},
   "source": [
    "# Extra [WIP]: dog or cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 # pip install opencv-python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.m6299etrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031125d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"/Users/fernandocosta/Downloads/dogs-vs-cats/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a524ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the image data\n",
    "def load_images(directory, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    counter = 100\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        while counter < 100: \n",
    "            counter += 1\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                img = cv2.imread(os.path.join(directory, filename))\n",
    "                img = cv2.resize(img, (100, 100))  # Resize the image to a fixed size\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n",
    "                images.append(img.flatten())  # Flatten the image and add it to the list\n",
    "                labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load cat images and assign labels (0 for cats)\n",
    "cat_images, cat_labels = load_images(base_directory + \"cats\", 0)\n",
    "\n",
    "# Load dog images and assign labels (1 for dogs)\n",
    "dog_images, dog_labels = load_images(base_directory + \"dogs\", 1)\n",
    "\n",
    "# Combine the cat and dog images and labels\n",
    "images = cat_images + dog_images\n",
    "labels = cat_labels + dog_labels\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a support vector machine (SVM) classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449babb",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Summary\n",
    "It's your turn, what have we learned today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f6718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-a",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
